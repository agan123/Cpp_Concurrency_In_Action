# 3.3 保护共享数据的替代设施

互斥量是最通用的机制，但其并非保护共享数据的唯一方式。这里有很多替代方式可以在特定情况下，提供更加合适的保护。

一个特别极端(但十分常见)的情况就是，共享数据只在初始化时进行并发访问，但是之后只需要隐式同步。这可能是因为数据一旦创建好之后就只读了，所以没有同步问题；或者因为作为对数据操作的一部分, 而隐式执行了必要的保护。无论哪种情况，数据初始化后锁住一个互斥量，纯粹是为了保护其初始化过程(这是没有必要的)，并且这会给性能带来不必要的冲击。出于以上的原因，`C++`标准提供了一种只保护共享数据初始化过程的机制。

## 3.3.1 保护共享数据的初始化过程

假设你有一个共享资源，它的构建代价很昂贵, 所以你想只在需要时创建; 它可能是打开一个数据库连接或分配出很多的内存。

*延迟初始化*(Lazy initialization)在单线程代码很常见——需要该资源的每个操作首先检查该资源是否已经初始化, 如果没有, 则在使用前初始化它：

```
std::shared_ptr<some_resource> resource_ptr;
void foo()
{
  if(!resource_ptr)
  {
    resource_ptr.reset(new some_resource);  // 1
  }
  resource_ptr->do_something();
}
```

如果共享数据本身对于并发访问是安全的，那么要把①转为多线程代码时，需要保护的只有初始化的部分，但是一种天真的转化如下面清单所示, 会使得访问该资源的线程产生不必要的序列化。这是因为每个线程必须等待互斥量，以确定该资源是否已经初始化了。

清单 3.11 使用一个互斥量的延迟初始化(线程安全)过程

```
std::shared_ptr<some_resource> resource_ptr;
std::mutex resource_mutex;

void foo()
{
  std::unique_lock<std::mutex> lk(resource_mutex);  // 所有线程在此序列化 
  if(!resource_ptr)
  {
    resource_ptr.reset(new some_resource);  // 只有初始化过程需要保护 
  }
  lk.unlock();
  resource_ptr->do_something();
}
```

这段代码足够常见, 也足够说明不必要的序列化的问题，也足够表现出没必要的线程化问题，很多人能想出更好的一些的办法来做这件事，包括声名狼藉的双重检查锁模式：

```
void undefined_behaviour_with_double_checked_locking()
{
  if(!resource_ptr)  // 1
  {
    std::lock_guard<std::mutex> lk(resource_mutex);
    if(!resource_ptr)  // 2
    {
      resource_ptr.reset(new some_resource);  // 3
    }
  }
  resource_ptr->do_something();  // 4
}
```

指针第一次读取数据不需要获取锁①，只有在指针为NULL时才需要获取锁。当获取锁之后，指针会被再次检查一遍② (这就是双重检查的部分)，避免另一的线程已经在第一次检查和获取锁之间做了初始化，并且让当前线程获取锁。

这个模式为什么声名狼藉呢？因为这里有潜在的条件竞争，未被锁保护的读取操作①没有与其他线程里被锁保护的写入操作③进行同步。因此就会产生条件竞争，这个条件竞争不仅覆盖指针本身，还会影响到其指向的对象；即使一个线程知道另一个线程完成对指针进行写入，它也可能没有看到新创建的some_resource实例，然后导致对错误的值调用do_something()④。这个例子是在一种典型的条件竞争——数据竞争，`C++`标准中这就会被认为是“未定义行为”。因此这绝对是要避免的。可以阅读第5章，那里有更多对内存模型的讨论，包括数据竞争的构成。

C++标准委员会也认为条件竞争的处理很重要，所以C++标准库提供了`std::once_flag`和`std::call_once`来处理这种情况。比起锁住互斥量，并显式的检查指针，每个线程只需要使用`std::call_once`，只需要知道在`std::call_once`的返回时，指针已经被某个线程初始化了(以一种合适的同步方式)。必须的同步数据保存在`std::once_flag`的实例中,每个`std::once_flag`实例对应着不同的初始化. 使用`std::call_once`比显式使用互斥量的负载要低，特别是当初始化完成后, 因此，如果它与所需的功能相匹配，应该优先使用它。下面的例子展示了与清单3.11中的同样的操作，这里使用了`std::call_once`重写。在这种情况下，初始化通过调用函数完成，同样也可以使用带有函数调用操作符的类的实例来完成。如同大多数在标准库中的函数一样，可以把函数或谓语(比如比较操作)作为参数，`std::call_once`可以和任何函数或可调用对象一起使用。

```
std::shared_ptr<some_resource> resource_ptr;
std::once_flag resource_flag;  // 1

void init_resource()
{
  resource_ptr.reset(new some_resource);
}

void foo()
{
  std::call_once(resource_flag,init_resource);  // 可以完整的进行一次初始化
  resource_ptr->do_something();
}
```

在这个例子中，`std::once_flag`①和初始化好的数据都是命名空间区域的对象，但是`std::call_once()`也可以方便地用于类成员的延迟初始化，如同下面的例子一样：

清单3.12 使用`std::call_once`对类成员延迟初始化(线程安全)

```
class X
{
private:
  connection_info connection_details;
  connection_handle connection;
  std::once_flag connection_init_flag;

  void open_connection()
  {
    connection=connection_manager.open(connection_details);
  }
public:
  X(connection_info const& connection_details_):
      connection_details(connection_details_)
  {}
  void send_data(data_packet const& data)  // 1
  {
    std::call_once(connection_init_flag,&X::open_connection,this);  // 2
    connection.send_data(data);
  }
  data_packet receive_data()  // 3
  {
    std::call_once(connection_init_flag,&X::open_connection,this);  // 2
    return connection.receive_data();
  }
};
```

例子中由第一个调用send_data()①或receive_data()③的线程完成初始化过程。使用成员函数open_connection()去初始化数据，也需要将this指针传进去。和其在在标准库中的接受可调用对象的函数一样，比如`std::thread`的构造函数和`std::bind()`，通过向`std::call_once()`②传递一个额外的参数来完成这个操作。

值得注意的是，`std::mutex`和`std::one_flag`的实例就不能拷贝或移动，所以当你想把他们作为类成员使用, 那么你需要显示定义这些用到了这里变量的特殊的成员函数。

还有一种情形的初始化过程中潜存着条件竞争：一个局部变量被声明为static类型。这种变量的初始化定义为代码首次经过它的声明时即进行初始化；对于多线程调用的函数，这就意味着这里有条件竞争——抢着去定义这个变量。在很多在前C++11编译器(译者：不支持C++11标准的编译器)，在实践过程中，这样的条件竞争是确实存在的，因为在多线程中，每个线程都认为他们是第一个,并且会去初始化这个变量；或一个线程要使用该变量,而另一个线程已经开始初始化,但还没完成。在C++11标准中，这些问题都被解决了：初始化明确定义为只发生在一个线程中，其他线程将会阻塞直到初始化完成，这样由哪个线程进行初始化的条件竞争问题就解决了，也不会有其他更多问题了。在只需要一个全局实例情况下，这里提供一个`std::call_once`的替代方案

```
class my_class;
my_class& get_my_class_instance()
{
  static my_class instance;  // 线程安全的初始化过程
  return instance;
}
```

多线程可以安全的调用get_my_class_instance()①函数，而不用担心初始化时的条件竞争。

只保护数据的初始化是更一般情况下的一种特殊情况: 数据很少更新。在大多数时间里，这种数据结构是只读的，因此可以多线程并发读取，但有时数据结构可能需要更新, 此时这里就需要一个保护机制。

## 3.3.2 保护很少更新的数据结构

试想，为了将域名解析为其相关IP地址，我们在缓存中的存放了一张DNS入口表。通常，给定的DNS入口, 在很长的一段时间内保持不变, 大部分情况下, 几年都不会变化。虽然，随着用户访问不同网站，新的入口可能会被添加到表中，但是这些数据可能在其生命周期内保持不变。所以定期检查缓存中入口的有效性，就变的十分重要了；但是，这也需要一次更新，也许这次更新只是对一些细节做了改动。

虽然更新频度很低，但更新也有可能发生，并且当这个缓存被多个线程访问时，为了确保没有线程读取到被破坏的数据结构, 就需要在更新时对这个缓存进行适当的保护。

如果没有专用数据结构--完全符合所需的用途，并且专门为并发更新和读取而设计(更多的例子在第6和第7章中介绍)，这样的更新要求线程独占数据结构的访问权，直到其完成更新操作。当更新完成，数据结构对于并发多线程访问又会是安全的。使用`std::mutex`来保护数据结构，显的有些反应过度，因为当不在修改时，它消除了并发访问数据结构的可能性。这里需要另一种不同的互斥量，这种互斥量常被称为“读写锁”，因为其允许两种不同的使用方式：一个“写”线程独占访问，多个“读”线程共享并发访问。

c++17标准库提供了两个这样的互斥量：`std::shared_mutex`和`std::shared_timed_mutex`, c++14只提供了`std::shared_timed_mutex`,c++11一个都没有提供. 如果你在使用c++14之前的编译器(即不支持c++14的编译器), 那么你可以使用boost库提供的实现. `std::shared_mutex`和`std::shared_timed_mutex`的区别是`std::shared_timed_mutex`支持额外的操作(在4.3节中讲述), 所以`std::shared_mutex`在一些平台上会有更好的性能, 如果你不需要额外的操作的话.

你将在第8章中看到，这种锁的也不能包治百病，其性能依赖于参与其中的处理器数量，同样也与读和更新线程的负载有关。为了确保增加复杂度后还能获得性能收益，目标系统上的代码性能分析就很重要。

这里将使用`std::shared_mutex`来替代`std::mutex`实例来进行同步。对于更新操作，可以使用`std::lock_guard<boost::shared_mutex>`和`std::unique_lock<boost::shared_mutex>`上锁, 代替相应的`std::mutex`模板特化. 与`std::mutex`所做的一样，这就能保证更新线程的独占访问。因为其他线程不需要去修改数据结构，所以其可以使用`boost::shared_lock<boost::shared_mutex>`获取共享访问权。这与使用`std::unique_lock`一样，除非多线程要在同时获取同一个`boost::shared_mutex`上有共享锁。唯一的限制：当任一线程拥有一个共享锁时，如果有一个线程尝试获取一个独占锁，那么它会阻塞, 直到所有其他线程放弃他们的锁；同样的，当任一线程拥有一个独占锁时，其他线程就无法获得共享锁或独占锁，直到第一个线程放弃其拥有的锁。

如同之前描述的那样，下面的代码清单展示了一个简单的DNS缓存，使用`std::map`持有缓存数据，使用`boost::shared_mutex`进行保护。

清单3.13 使用`boost::shared_mutex`对数据结构进行保护

```
#include <map>
#include <string>
#include <mutex>
#include <boost/thread/shared_mutex.hpp>

class dns_entry;

class dns_cache
{
  std::map<std::string,dns_entry> entries;
  mutable boost::shared_mutex entry_mutex;
public:
  dns_entry find_entry(std::string const& domain) const
  {
    boost::shared_lock<boost::shared_mutex> lk(entry_mutex);  // 1
    std::map<std::string,dns_entry>::const_iterator const it=
       entries.find(domain);
    return (it==entries.end())?dns_entry():it->second;
  }
  void update_or_add_entry(std::string const& domain,
                           dns_entry const& dns_details)
  {
    std::lock_guard<boost::shared_mutex> lk(entry_mutex);  // 2
    entries[domain]=dns_details;
  }
};
```

清单3.13中，find_entry()使用`boost::shared_lock<>`来保护共享和只读权限①；这就使得多线程可以同时调用find_entry()，且不会出错。另一方面，update_or_add_entry()使用`std::lock_guard<>`实例，当表格需要更新时②，为其提供独占访问权限；update_or_add_entry()函数调用时，独占锁会阻止其他线程对数据结构进行修改，并且阻止线程调用find_entry()。

## 3.3.3 嵌套锁

当一个线程已经获取一个`std::mutex`时(已经上锁)，并对其再次上锁，这个操作就是错误的，并且尝试这样做会产生未定义行为。然而，在某些情况下，一个线程需要重复获取同一个互斥量多次，并且不先释放掉。为了这一目的，`C++`标准库提供了`std::recursive_mutex`类。其功能与`std::mutex`类似，除了你可以在同一线程上对一个实例多次上锁。在其他线程锁住该互斥量前，你必须释放你拥有的(这个互斥量的)所有锁，所以当你调用lock()三次时，你也必须调用unlock()三次。正确使用`std::lock_guard<std::recursive_mutex>`和`std::unique_lock<std::recursive_mutex>`可以帮你处理这些问题。

大多数情况下，当你需要嵌套锁时，就要对你的设计进行改动。嵌套锁一般用在可并发访问的类上，所以其拥互斥量保护其成员数据。每个公共成员函数都会对互斥量上锁，然后完成对应的功能，之后再解锁互斥量。不过，有时一个公共成员函数会调用另一个成员函数，这种情况下，第二个成员函数也会试图锁住互斥量，这就会导致未定义行为的发生。“变通的”解决方案会将互斥量转为嵌套锁，第二个成员函数就能成功的进行上锁，并且函数能继续执行。

但是，这样的使用方式是不推荐的，因为其过于草率，并且不合理。特别是，当锁被持有时，对应类的不变量通常正在被修改。这意味着，即使当不变量正在改变的时候，第二个成员函数还需要继续执行。一个比较好的方式是，从中提取出一个函数作为类的私有成员，并且让其他成员函数都对其进行调用，这个私有成员函数不会对互斥量进行上锁(在调用前必须获得锁)。然后，你仔细考虑一下，在这种情况调用新函数时，数据的状态。

-------

[3] Howard E. Hinnant, “Multithreading API for C++0X—A Layered Approach,” C++ Standards Committee Paper N2094, http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2094.html.
